@inproceedings{abdallah-etal-2025-asrank,
    title = "{ASR}ank: Zero-Shot Re-Ranking with Answer Scent for Document Retrieval",
    author = "Abdallah, Abdelrahman  and
      Mozafari, Jamshid  and
      Piryani, Bhawna  and
      Jatowt, Adam",
    editor = "Chiruzzo, Luis  and
      Ritter, Alan  and
      Wang, Lu",
    booktitle = "Findings of the Association for Computational Linguistics: NAACL 2025",
    month = apr,
    year = "2025",
    address = "Albuquerque, New Mexico",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2025.findings-naacl.161/",
    doi = "10.18653/v1/2025.findings-naacl.161",
    pages = "2950--2970",
    ISBN = "979-8-89176-195-7",
    abstract = "Retrieval-Augmented Generation (RAG) models have drawn considerable attention in modern open-domain question answering. The effectiveness of RAG depends on the quality of the top retrieved documents. However, conventional retrieval methods sometimes fail to rank the most relevant documents at the top. In this paper, we introduce ASRANK, a new re-ranking method based on scoring retrieved documents using zero-shot answer scent which relies on a pre-trained large language model to compute the likelihood of the document-derived answers aligning with the answer scent. Our approach demonstrates marked improvements across several datasets, including NQ, TriviaQA, WebQA, ArchivalQA, HotpotQA, and Entity Questions. Notably, ASRANK increases Top-1 retrieval accuracy on NQ from 19.2{\%} to 46.5{\%} for MSS and 22.1{\%} to 47.3{\%} for BM25. It also shows strong retrieval performance on several datasets compared to state-of-the-art methods (47.3 Top-1 by ASRANK vs 35.4 by UPR by BM25)."
}
